{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maverick-0215/Fairness-via-Continual-Learning/blob/main/Testing_Fairness_with_EWC_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR2JDiasuRGD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "           'hours-per-week', 'native-country', 'income']\n",
        "data = pd.read_csv(url, header=None, names=columns, na_values=\" ?\")\n",
        "\n",
        "data = pd.get_dummies(data, columns=data.select_dtypes(include=['object']).columns)\n",
        "\n",
        "y = data['income_ >50K'].values\n",
        "\n",
        "# Drop 'income' related columns from X\n",
        "X = data.drop(['income_ <=50K', 'income_ >50K'], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "gender_attr = data['sex_ Male'].values  # 1 for Male, 0 for Female\n",
        "race_attr = data['race_ White'].values  # 1 for White, 0 for Black\n",
        "\n",
        "# Filter data for White and Black individuals only\n",
        "valid_race = (data['race_ White'] == 1) | (data['race_ Black'] == 1)\n",
        "X_tensor = X_tensor[valid_race]\n",
        "y_tensor = y_tensor[valid_race]\n",
        "gender_attr = gender_attr[valid_race]\n",
        "race_attr = race_attr[valid_race]\n",
        "\n",
        "X_train, X_test, y_train, y_test, gender_train, gender_test, race_train, race_test = train_test_split(\n",
        "    X_tensor, y_tensor, gender_attr, race_attr, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "1UI8T0yX0a8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class AdultDataset(Dataset):\n",
        "    def __init__(self, X, y, gender_attrs, race_attrs):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.gender_attrs = gender_attrs\n",
        "        self.race_attrs = race_attrs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index], self.gender_attrs[index], self.race_attrs[index]\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = AdultDataset(X_train, y_train, gender_train, race_train)\n",
        "test_dataset = AdultDataset(X_test, y_test, gender_test, race_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "SrWyZ5U6u2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # Output is 2 because it's a binary classification problem\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels, _,_ in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return total_loss / len(loader), accuracy\n"
      ],
      "metadata": {
        "id": "lCH4v0AuwtBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fairness_metrics(true_labels, preds, race_attrs, gender_attrs):\n",
        "    metrics = {}\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    true_labels = np.array(true_labels)\n",
        "    preds = np.array(preds)\n",
        "    race_attrs = np.array(race_attrs)  # Assuming 1 = White, 0 = Black\n",
        "    gender_attrs = np.array(gender_attrs)  # Assuming 1 = Male, 0 = Female\n",
        "\n",
        "    groups = {\n",
        "        \"White Male\": (race_attrs == 1) & (gender_attrs == 1),\n",
        "        \"White Female\": (race_attrs == 1) & (gender_attrs == 0),\n",
        "        \"Black Male\": (race_attrs == 0) & (gender_attrs == 1),\n",
        "        \"Black Female\": (race_attrs == 0) & (gender_attrs == 0),\n",
        "    }\n",
        "\n",
        "    pos_rates = {}\n",
        "    tpr_rates = {}\n",
        "    fpr_rates = {}\n",
        "\n",
        "    for group_name, group_idx in groups.items():\n",
        "        if np.sum(group_idx) == 0:\n",
        "            continue  # Skip groups with no samples\n",
        "\n",
        "        pos_rate = np.mean(preds[group_idx])\n",
        "        cm = confusion_matrix(true_labels[group_idx], preds[group_idx], labels=[0, 1])\n",
        "\n",
        "        tpr = cm[1, 1] / (cm[1, 1] + cm[1, 0]) if (cm[1, 1] + cm[1, 0]) > 0 else 0\n",
        "        fpr = cm[0, 1] / (cm[0, 1] + cm[0, 0]) if (cm[0, 1] + cm[0, 0]) > 0 else 0\n",
        "\n",
        "        pos_rates[group_name] = pos_rate\n",
        "        tpr_rates[group_name] = tpr\n",
        "        fpr_rates[group_name] = fpr\n",
        "\n",
        "    # Compute fairness metrics\n",
        "    metrics[\"Demographic Parity\"] = max(pos_rates.values()) - min(pos_rates.values())\n",
        "    metrics[\"Equalized Odds (TPR Difference)\"] = max(tpr_rates.values()) - min(tpr_rates.values())\n",
        "    metrics[\"Equalized Odds (FPR Difference)\"] = max(fpr_rates.values()) - min(fpr_rates.values())\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "ZOq-gIezKF79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_sensitive_attrs_gender = []\n",
        "    all_sensitive_attrs_race = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            if len(batch) == 4:\n",
        "                inputs, labels, gender, race = batch\n",
        "                all_sensitive_attrs_gender.extend(gender.cpu().numpy())\n",
        "                all_sensitive_attrs_race.extend(race.cpu().numpy())\n",
        "            elif len(batch) == 3:\n",
        "                inputs, labels, sensitive = batch\n",
        "                all_sensitive_attrs_gender.extend(sensitive.cpu().numpy())  # Assuming gender in this case\n",
        "            elif len(batch) == 2:\n",
        "                inputs, labels = batch\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected batch format with {len(batch)} elements.\")\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Compute fairness metrics and per-group accuracy\n",
        "    if all_sensitive_attrs_gender and all_sensitive_attrs_race:\n",
        "        fairness_metrics = calculate_fairness_metrics(\n",
        "            all_labels, all_preds, all_sensitive_attrs_race, all_sensitive_attrs_gender\n",
        "        )\n",
        "\n",
        "        # Compute accuracy for each subgroup\n",
        "        all_preds = np.array(all_preds)\n",
        "        all_labels = np.array(all_labels)\n",
        "        all_sensitive_attrs_race = np.array(all_sensitive_attrs_race)\n",
        "        all_sensitive_attrs_gender = np.array(all_sensitive_attrs_gender)\n",
        "\n",
        "        groups = {\n",
        "            \"White Male\": (all_sensitive_attrs_race == 1) & (all_sensitive_attrs_gender == 1),\n",
        "            \"White Female\": (all_sensitive_attrs_race == 1) & (all_sensitive_attrs_gender == 0),\n",
        "            \"Black Male\": (all_sensitive_attrs_race == 0) & (all_sensitive_attrs_gender == 1),\n",
        "            \"Black Female\": (all_sensitive_attrs_race == 0) & (all_sensitive_attrs_gender == 0),\n",
        "        }\n",
        "\n",
        "        group_accuracies = {}\n",
        "        for group_name, group_idx in groups.items():\n",
        "            if np.sum(group_idx) > 0:\n",
        "                group_acc = (all_preds[group_idx] == all_labels[group_idx]).sum() / np.sum(group_idx)\n",
        "                group_accuracies[group_name] = group_acc * 100\n",
        "            else:\n",
        "                group_accuracies[group_name] = None  # Handle empty groups\n",
        "\n",
        "    else:\n",
        "        fairness_metrics = {}\n",
        "        group_accuracies = {}\n",
        "\n",
        "    return total_loss / len(loader), accuracy, fairness_metrics, group_accuracies\n",
        "\n",
        "# Training and Evaluation Loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = NeuralNet(input_size=X_train.shape[1]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "epochs = 10\n",
        "\n",
        "avg_dp = 0\n",
        "avg_eo_diff_tpr = 0\n",
        "avg_eo_diff_fpr = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss, test_acc, fairness_metrics, group_accuracies = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}% \"\n",
        "          f\"- Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "\n",
        "    # print(\"Subgroup Accuracies:\")\n",
        "    # for group, acc in group_accuracies.items():\n",
        "    #     print(f\"{group}: {acc:.2f}%\" if acc is not None else f\"{group}: No samples in batch\")\n",
        "\n",
        "    avg_dp += fairness_metrics.get('Demographic Parity', 0)\n",
        "    avg_eo_diff_tpr += fairness_metrics.get('Equalized Odds (TPR Difference)', 0)\n",
        "    avg_eo_diff_fpr += fairness_metrics.get('Equalized Odds (FPR Difference)', 0)\n",
        "\n",
        "# Print Final Fairness Metrics\n",
        "print(\"\\nFinal Fairness Metrics:\")\n",
        "print(f\"Average Demographic Parity = {avg_dp / epochs:.4f}\")\n",
        "print(f\"Average Equalized Odds (TPR Difference) = {avg_eo_diff_tpr / epochs:.4f}\")\n",
        "print(f\"Average Equalized Odds (FPR Difference) = {avg_eo_diff_fpr / epochs:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cIU8ToKJw5Oi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153d500d-6bef-4460-e998-2769e7bc7efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Train Loss: 0.3445, Train Accuracy: 83.96% - Test Loss: 0.3295, Test Accuracy: 84.92%\n",
            "\n",
            "Epoch [2/10] - Train Loss: 0.3202, Train Accuracy: 85.08% - Test Loss: 0.3226, Test Accuracy: 85.33%\n",
            "\n",
            "Epoch [3/10] - Train Loss: 0.3131, Train Accuracy: 85.55% - Test Loss: 0.3210, Test Accuracy: 85.52%\n",
            "\n",
            "Epoch [4/10] - Train Loss: 0.3082, Train Accuracy: 85.64% - Test Loss: 0.3271, Test Accuracy: 85.20%\n",
            "\n",
            "Epoch [5/10] - Train Loss: 0.3067, Train Accuracy: 85.77% - Test Loss: 0.3239, Test Accuracy: 85.10%\n",
            "\n",
            "Epoch [6/10] - Train Loss: 0.3045, Train Accuracy: 85.91% - Test Loss: 0.3179, Test Accuracy: 85.31%\n",
            "\n",
            "Epoch [7/10] - Train Loss: 0.3024, Train Accuracy: 85.77% - Test Loss: 0.3193, Test Accuracy: 85.10%\n",
            "\n",
            "Epoch [8/10] - Train Loss: 0.3003, Train Accuracy: 86.11% - Test Loss: 0.3224, Test Accuracy: 85.47%\n",
            "\n",
            "Epoch [9/10] - Train Loss: 0.2981, Train Accuracy: 86.17% - Test Loss: 0.3255, Test Accuracy: 85.13%\n",
            "\n",
            "Epoch [10/10] - Train Loss: 0.2943, Train Accuracy: 86.14% - Test Loss: 0.3233, Test Accuracy: 85.23%\n",
            "\n",
            "\n",
            "Final Fairness Metrics:\n",
            "Average Demographic Parity = 0.2346\n",
            "Average Equalized Odds (TPR Difference) = 0.2601\n",
            "Average Equalized Odds (FPR Difference) = 0.0846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above results are just for normal nn trained on the whole data(males + females)\n",
        "\n"
      ],
      "metadata": {
        "id": "3hIeQHXwz_9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training nn with Task A(only male data) and Task B(only female data) with EWC loss function."
      ],
      "metadata": {
        "id": "sbHUFlgd0L64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate data into four groups: White Male, White Female, Black Male, Black Female\n",
        "white_male_data = data[(data['race_ White'] == 1) & (data['sex_ Male'] == 1)]\n",
        "white_female_data = data[(data['race_ White'] == 1) & (data['sex_ Male'] == 0)]\n",
        "black_male_data = data[(data['race_ Black'] == 1) & (data['sex_ Male'] == 1)]\n",
        "black_female_data = data[(data['race_ Black'] == 1) & (data['sex_ Male'] == 0)]\n",
        "\n",
        "# Function to process each group\n",
        "def process_group(group_data):\n",
        "    X = group_data.drop(['income_ <=50K', 'income_ >50K'], axis=1).values\n",
        "    y = group_data['income_ >50K'].values  # 1 if '>50K', 0 if '<=50K'\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    return train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Process each group\n",
        "X_white_male_train, X_white_male_test, y_white_male_train, y_white_male_test = process_group(white_male_data)\n",
        "X_white_female_train, X_white_female_test, y_white_female_train, y_white_female_test = process_group(white_female_data)\n",
        "X_black_male_train, X_black_male_test, y_black_male_train, y_black_male_test = process_group(black_male_data)\n",
        "X_black_female_train, X_black_female_test, y_black_female_train, y_black_female_test = process_group(black_female_data)\n"
      ],
      "metadata": {
        "id": "Rn2QC03M26Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_white_male_train))\n",
        "print(len(X_white_female_train))\n",
        "print(len(X_black_male_train))\n",
        "print(len(X_black_female_train))\n",
        "print(len(X_white_male_test))\n",
        "print(len(X_white_female_test))\n",
        "print(len(X_black_male_test))\n",
        "print(len(X_black_female_test))"
      ],
      "metadata": {
        "id": "KJj-RksABsVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981ba325-516a-4b50-882a-73adaea0cdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15339\n",
            "6913\n",
            "1255\n",
            "1244\n",
            "3835\n",
            "1729\n",
            "314\n",
            "311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataLoaders for the four groups\n",
        "train_dataset_A = AdultDataset(\n",
        "    X_white_male_train, y_white_male_train,\n",
        "    gender_attrs=np.ones(len(y_white_male_train)),  # Male = 1\n",
        "    race_attrs=np.ones(len(y_white_male_train))  # White = 1\n",
        ")\n",
        "\n",
        "train_dataset_B = AdultDataset(\n",
        "    X_white_female_train, y_white_female_train,\n",
        "    gender_attrs=np.zeros(len(y_white_female_train)),  # Female = 0\n",
        "    race_attrs=np.ones(len(y_white_female_train))  # White = 1\n",
        ")\n",
        "\n",
        "train_dataset_C = AdultDataset(\n",
        "    X_black_male_train, y_black_male_train,\n",
        "    gender_attrs=np.ones(len(y_black_male_train)),  # Male = 1\n",
        "    race_attrs=np.zeros(len(y_black_male_train))  # Black = 0\n",
        ")\n",
        "\n",
        "train_dataset_D = AdultDataset(\n",
        "    X_black_female_train, y_black_female_train,\n",
        "    gender_attrs=np.zeros(len(y_black_female_train)),  # Female = 0\n",
        "    race_attrs=np.zeros(len(y_black_female_train))  # Black = 0\n",
        ")\n",
        "\n",
        "# Creating DataLoaders\n",
        "train_loader_A = DataLoader(train_dataset_A, batch_size=64, shuffle=True)\n",
        "train_loader_B = DataLoader(train_dataset_B, batch_size=64, shuffle=True)\n",
        "train_loader_C = DataLoader(train_dataset_C, batch_size=64, shuffle=True)\n",
        "train_loader_D = DataLoader(train_dataset_D, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "A21shsNWBxzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, loss, and optimizer for Task A (White Male)\n",
        "model = NeuralNet(input_size=X_white_male_train.shape[1]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "epochs = 10\n",
        "\n",
        "# Train on Task A (White Male)\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train(model, train_loader_A, criterion, optimizer, device)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}% (Task A: White Male)\")\n",
        "\n",
        "# Save model parameters after Task A\n",
        "old_params_A = {name: param.clone().detach() for name, param in model.named_parameters() if param.requires_grad}\n"
      ],
      "metadata": {
        "id": "7QLgq5E3EfZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb795734-140c-4ab2-de7d-1fbaf904698e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Train Loss: 0.4275, Train Accuracy: 79.11% (Task A: White Male)\n",
            "Epoch [2/10] - Train Loss: 0.3974, Train Accuracy: 81.04% (Task A: White Male)\n",
            "Epoch [3/10] - Train Loss: 0.3917, Train Accuracy: 81.35% (Task A: White Male)\n",
            "Epoch [4/10] - Train Loss: 0.3872, Train Accuracy: 81.31% (Task A: White Male)\n",
            "Epoch [5/10] - Train Loss: 0.3842, Train Accuracy: 81.85% (Task A: White Male)\n",
            "Epoch [6/10] - Train Loss: 0.3792, Train Accuracy: 81.69% (Task A: White Male)\n",
            "Epoch [7/10] - Train Loss: 0.3764, Train Accuracy: 82.16% (Task A: White Male)\n",
            "Epoch [8/10] - Train Loss: 0.3740, Train Accuracy: 82.21% (Task A: White Male)\n",
            "Epoch [9/10] - Train Loss: 0.3742, Train Accuracy: 82.04% (Task A: White Male)\n",
            "Epoch [10/10] - Train Loss: 0.3723, Train Accuracy: 82.18% (Task A: White Male)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fisher_information(model, dataloader, criterion, device):\n",
        "    model.train()  # Prevents issues with batch norm and dropout\n",
        "    fisher_information = {name: torch.zeros_like(param) for name, param in model.named_parameters() if param.requires_grad}\n",
        "\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        if len(batch) == 3:  # (inputs, labels, sensitive_attrs)\n",
        "            inputs, labels, _ = batch\n",
        "        elif len(batch) == 4:  # (inputs, labels, sensitive_attrs, race_attrs)\n",
        "            inputs, labels, _, _ = batch  # Ignore last two values\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected batch format: {len(batch)} elements\")\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        total_samples += batch_size\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                fisher_information[name] += (param.grad.pow(2) * batch_size).detach()\n",
        "\n",
        "    # Normalize the Fisher Information Matrix\n",
        "    for name in fisher_information:\n",
        "        fisher_information[name] /= total_samples\n",
        "\n",
        "    return fisher_information\n",
        "fisher_information_A = calculate_fisher_information(model, train_loader_A, criterion, device)"
      ],
      "metadata": {
        "id": "IAfhJrEzOYiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_ewc(model, train_loader, criterion, optimizer, fisher_information, old_params, device,\n",
        "                   ewc_lambda, max_epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            if len(batch) == 3:\n",
        "                inputs, labels, _ = batch\n",
        "            elif len(batch) == 4:\n",
        "                inputs, labels, _, _ = batch\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected batch format: {len(batch)} elements\")\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Compute EWC Loss\n",
        "            ewc_loss = 0.0\n",
        "            for (name, param), (_, old_param) in zip(model.named_parameters(), old_params.items()):\n",
        "                if name in fisher_information:\n",
        "                    ewc_loss += (fisher_information[name] * (param - old_param).pow(2)).sum()\n",
        "\n",
        "            total_loss = loss + (ewc_lambda * ewc_loss)\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "ryU-UMb6Op7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_sensitive_attrs_gender = []\n",
        "    all_sensitive_attrs_race = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            if len(batch) == 4:\n",
        "                inputs, labels, gender, race = batch\n",
        "                all_sensitive_attrs_gender.extend(gender.cpu().numpy())\n",
        "                all_sensitive_attrs_race.extend(race.cpu().numpy())\n",
        "            elif len(batch) == 3:\n",
        "                inputs, labels, sensitive = batch\n",
        "                all_sensitive_attrs_gender.extend(sensitive.cpu().numpy())  # Assuming gender in this case\n",
        "            elif len(batch) == 2:\n",
        "                inputs, labels = batch\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected batch format with {len(batch)} elements.\")\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Compute fairness metrics and per-group accuracy\n",
        "    if all_sensitive_attrs_gender and all_sensitive_attrs_race:\n",
        "        fairness_metrics = calculate_fairness_metrics(\n",
        "            all_labels, all_preds, all_sensitive_attrs_race, all_sensitive_attrs_gender\n",
        "        )\n",
        "\n",
        "        # Compute accuracy for each subgroup\n",
        "        all_preds = np.array(all_preds)\n",
        "        all_labels = np.array(all_labels)\n",
        "        all_sensitive_attrs_race = np.array(all_sensitive_attrs_race)\n",
        "        all_sensitive_attrs_gender = np.array(all_sensitive_attrs_gender)\n",
        "\n",
        "        groups = {\n",
        "            \"White Male\": (all_sensitive_attrs_race == 1) & (all_sensitive_attrs_gender == 1),\n",
        "            \"White Female\": (all_sensitive_attrs_race == 1) & (all_sensitive_attrs_gender == 0),\n",
        "            \"Black Male\": (all_sensitive_attrs_race == 0) & (all_sensitive_attrs_gender == 1),\n",
        "            \"Black Female\": (all_sensitive_attrs_race == 0) & (all_sensitive_attrs_gender == 0),\n",
        "        }\n",
        "\n",
        "        group_accuracies = {}\n",
        "        for group_name, group_idx in groups.items():\n",
        "            if np.sum(group_idx) > 0:\n",
        "                group_acc = (all_preds[group_idx] == all_labels[group_idx]).sum() / np.sum(group_idx)\n",
        "                group_accuracies[group_name] = group_acc * 100\n",
        "            else:\n",
        "                group_accuracies[group_name] = None  # Handle empty groups\n",
        "\n",
        "    else:\n",
        "        fairness_metrics = {}\n",
        "        group_accuracies = {}\n",
        "\n",
        "    return total_loss / len(loader), accuracy, fairness_metrics, group_accuracies\n"
      ],
      "metadata": {
        "id": "qsWbfa18wfpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define EWC regularization strength\n",
        "ewc_lambda = 100\n",
        "epochs = 1\n",
        "\n",
        "# Train sequentially on Task B (White Female)\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_with_ewc(model, train_loader_B, criterion, optimizer,\n",
        "                                           fisher_information_A, old_params_A, device, ewc_lambda)\n",
        "# Update Fisher Information and Parameters for Task B\n",
        "fisher_information_B = calculate_fisher_information(model, train_loader_B, criterion, device)\n",
        "old_params_B = {name: param.clone().detach() for name, param in model.named_parameters() if param.requires_grad}\n",
        "\n",
        "# Train sequentially on Task C (Black Male)\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_with_ewc(model, train_loader_C, criterion, optimizer,\n",
        "                                           fisher_information_B, old_params_B, device, ewc_lambda)\n",
        "# Update Fisher Information and Parameters for Task C\n",
        "fisher_information_C = calculate_fisher_information(model, train_loader_C, criterion, device)\n",
        "old_params_C = {name: param.clone().detach() for name, param in model.named_parameters() if param.requires_grad}\n",
        "\n",
        "# Train sequentially on Task D (Black Female)\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_with_ewc(model, train_loader_D, criterion, optimizer,\n",
        "                                           fisher_information_C, old_params_C, device, ewc_lambda)\n",
        "\n",
        "# Final evaluation after all tasks\n",
        "test_loss, test_acc, fairness_metrics, group_accuracies = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "# Print final accuracy after training on all tasks\n",
        "print(f\"\\nTraining completed for Task D (Black Female) with EWC.\")\n",
        "print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# Display subgroup accuracies\n",
        "print(\"\\nSubgroup Accuracies:\")\n",
        "for group, acc in group_accuracies.items():\n",
        "    print(f\"{group}: {acc:.2f}%\" if acc is not None else f\"{group}: No samples in batch\")\n",
        "\n",
        "# Display fairness metrics after all tasks\n",
        "print(\"\\nFairness Metrics after training on all tasks (A → B → C → D):\")\n",
        "print(f\"Demographic Parity: {fairness_metrics['Demographic Parity']:.4f}\")\n",
        "print(f\"Equalized Odds (TPR Difference): {fairness_metrics['Equalized Odds (TPR Difference)']:.4f}\")\n",
        "print(f\"Equalized Odds (FPR Difference): {fairness_metrics['Equalized Odds (FPR Difference)']:.4f}\")\n"
      ],
      "metadata": {
        "id": "UwIas7JqQXie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f931a7-23df-4976-b9a3-b10962680db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training completed for Task D (Black Female) with EWC.\n",
            "Final Test Accuracy: 81.95%\n",
            "\n",
            "Subgroup Accuracies:\n",
            "White Male: 76.84%\n",
            "White Female: 90.41%\n",
            "Black Male: 82.01%\n",
            "Black Female: 96.51%\n",
            "\n",
            "Fairness Metrics after training on all tasks (A → B → C → D):\n",
            "Demographic Parity: 0.1158\n",
            "Equalized Odds (TPR Difference): 0.1212\n",
            "Equalized Odds (FPR Difference): 0.0251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iK-fPo3rKy30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}